{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n",
      "Requirement already satisfied: torch==1.13.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision==0.14.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.14.1)\n",
      "Requirement already satisfied: diffusers==0.18.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.18.2)\n",
      "Requirement already satisfied: scikit-image==0.19.3 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.19.3)\n",
      "Requirement already satisfied: scikit-video==1.1.11 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (1.1.11)\n",
      "Requirement already satisfied: zarr==2.12.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: numcodecs==0.10.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.10.2)\n",
      "Requirement already satisfied: pygame==2.1.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: pymunk==6.2.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (6.2.1)\n",
      "Requirement already satisfied: gym==0.26.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.26.2)\n",
      "Requirement already satisfied: shapely==1.8.4 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (1.8.4)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: requests in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torchvision==0.14.1) (2.32.3)\n",
      "Requirement already satisfied: numpy in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torchvision==0.14.1) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torchvision==0.14.1) (10.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (0.23.4)\n",
      "Requirement already satisfied: importlib-metadata in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (7.1.0)\n",
      "Requirement already satisfied: filelock in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (3.15.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (2024.5.15)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (3.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (2.34.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (1.13.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (2024.6.18)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (24.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (1.6.0)\n",
      "Requirement already satisfied: asciitree in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from zarr==2.12.0) (0.3.3)\n",
      "Requirement already satisfied: fasteners in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from zarr==2.12.0) (0.19)\n",
      "Requirement already satisfied: entrypoints in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from numcodecs==0.10.2) (0.4)\n",
      "Requirement already satisfied: cffi>=1.15.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from pymunk==6.2.1) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from gym==0.26.2) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from gym==0.26.2) (0.0.8)\n",
      "Requirement already satisfied: setuptools in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (59.6.0)\n",
      "Requirement already satisfied: wheel in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.43.0)\n",
      "Requirement already satisfied: pycparser in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from cffi>=1.15.0->pymunk==6.2.1) (2.22)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.18.2) (2024.6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.18.2) (4.66.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.18.2) (6.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.18.2) (3.19.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Installing pip packages**\n",
    "#@markdown - Diffusion Model: [PyTorch](https://pytorch.org) & [HuggingFace diffusers](https://huggingface.co/docs/diffusers/index)\n",
    "#@markdown - Dataset Loading: [Zarr](https://zarr.readthedocs.io/en/stable/) & numcodecs\n",
    "#@markdown - Push-T Env: gym, pygame, pymunk & shapely\n",
    "!python --version\n",
    "!pip3 install torch==1.13.1 torchvision==0.14.1 diffusers==0.18.2 \\\n",
    "scikit-image==0.19.3 scikit-video==1.1.11 zarr==2.12.0 numcodecs==0.10.2 \\\n",
    "pygame==2.1.2 pymunk==6.2.1 gym==0.26.2 shapely==1.8.4 \\\n",
    "# &> /dev/null # mute output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### **Imports**\n",
    "# diffusion policy import\n",
    "from typing import Tuple, Sequence, Dict, Union, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "# import zarr\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# # env import\n",
    "# import gym\n",
    "# from gym import spaces\n",
    "# import pygame\n",
    "# import pymunk\n",
    "# import pymunk.pygame_util\n",
    "# from pymunk.space_debug_draw_options import SpaceDebugColor\n",
    "# from pymunk.vec2d import Vec2d\n",
    "# import shapely.geometry as sg\n",
    "# import cv2\n",
    "# import skimage.transform as st\n",
    "# from skvideo.io import vwrite\n",
    "# from IPython.display import Video\n",
    "# import gdown\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exo_state dataset with utility functions\n",
    "\n",
    "class ExoStateDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A class to prepare and load the exo state dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_file_path_1: str,\n",
    "                csv_file_path_2: str,\n",
    "                episode_stats: dict[str, list],\n",
    "                obs_horizon: int = 10,\n",
    "                pred_horizon: int = 10,\n",
    "                decimation_factor = 1,\n",
    "                train=True):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            csv_file_path_1 (str): The path to the csv file containing the patient dataset.\n",
    "            csv_file_path_2 (str): The path to the csv file containing the instructor dataset.\n",
    "            episode_stats (dict[str, list]): A dictionary containing the episode stats (start and end indices).\n",
    "            obs_horizon (int): The observation horizon.\n",
    "            pred_horizon (int): The prediction horizon.\n",
    "            decimation_factor (int): The decimation factor for the dataset. This number is used to determine sampling frequency.\n",
    "            train (bool): Whether the dataset is for training or testing. Default is True.\n",
    "        \"\"\"\n",
    "        # Load only the required decimated data\n",
    "        # combine data from the two csv files\n",
    "        self.data, self.episode_lengths = self.load_and_combine_data(csv_file_path_1, csv_file_path_2, episode_stats, decimation_factor)\n",
    "\n",
    "        # if the dataset is for training, normalize the data\n",
    "        if train:\n",
    "            # compute the statictics for normalization\n",
    "            self.stats = self.get_data_stats(self.data)\n",
    "            # normalize the data\n",
    "            self.data = self.normalize_data(self.data, self.stats)\n",
    "\n",
    "        # create sample indices\n",
    "        sequence_length = obs_horizon + pred_horizon\n",
    "        self.indices = self.create_sample_indices(sequence_length)\n",
    "\n",
    "        self.obs_horizon = obs_horizon\n",
    "        self.pred_horizon = pred_horizon\n",
    "\n",
    "    def load_and_combine_data(self, csv_file_path_1: str, csv_file_path_2: str, episode_stats: dict[str, list], decimation_factor: int = 1):\n",
    "        \"\"\"\n",
    "        Load, decimate and combine data from the two csv files.\n",
    "        \"\"\"\n",
    "\n",
    "        chunks = []\n",
    "        episode_lengths = []\n",
    "\n",
    "        for start, end in zip(episode_stats[\"start\"], episode_stats[\"end\"]):\n",
    "            # Load the required chunk of data and apply decimation in one step\n",
    "            # remove first row (header) and 1st column (time)\n",
    "            chunk_1 = pd.read_csv(csv_file_path_1, \n",
    "                                    skiprows = lambda x: x < start or (x - start) % decimation_factor != 0,\n",
    "                                    nrows = (end - start) // decimation_factor + 1,\n",
    "                                    usecols = lambda x: x != 0)\n",
    "            chunk_2 = pd.read_csv(csv_file_path_2, \n",
    "                                    skiprows = lambda x: x < start or (x - start) % decimation_factor != 0,\n",
    "                                    nrows = (end - start) // decimation_factor + 1,\n",
    "                                    usecols = lambda x: x != 0)\n",
    "\n",
    "            # confirm that the two chunks have the same length\n",
    "            assert len(chunk_1) == len(chunk_2)\n",
    "\n",
    "            # horizontal concatenation\n",
    "            chunk = pd.concat([chunk_1, chunk_2], axis=1)\n",
    "\n",
    "            # confirm that the chunk has the correct length\n",
    "            assert len(chunk) == len(chunk_1)\n",
    "\n",
    "            # Append the chunk to the list\n",
    "            chunks.append(chunk)\n",
    "            episode_lengths.append(len(chunk))\n",
    "\n",
    "        # Combine the chunks into a single dataframe\n",
    "        data = pd.concat(chunks, axis=0)\n",
    "\n",
    "        return data, episode_lengths\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_data_stats(data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Compute the min and max values of the given dataset.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The dataset.       \n",
    "        \"\"\"\n",
    "\n",
    "        return {\n",
    "            \"min\": np.min(data, axis=0),\n",
    "            \"max\": np.max(data, axis=0),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_data(data: pd.DataFrame, stats: dict):\n",
    "        \"\"\"\n",
    "        Normalize the given dataset.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The dataset.\n",
    "            stats (dict): The statistics of the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # normalize to [0, 1]\n",
    "        ndata = (data - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"])\n",
    "        # normalize to [-1, 1]\n",
    "        ndata = 2 * ndata - 1\n",
    "\n",
    "        return ndata\n",
    "\n",
    "    @staticmethod\n",
    "    def unnormalize_data(ndata: pd.DataFrame, stats: dict):\n",
    "        \"\"\"\n",
    "        Unnormalize the given dataset.\n",
    "\n",
    "        Args:\n",
    "            ndata (pd.DataFrame): The normalized dataset.\n",
    "            stats (dict): The statistics of the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # unnormalize to [0, 1]\n",
    "        data = (ndata + 1) / 2\n",
    "        # unnormalize to original range\n",
    "        data = data * (stats[\"max\"] - stats[\"min\"]) + stats[\"min\"]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def create_sample_indices(self, sequence_length: int):\n",
    "        \"\"\"\n",
    "        Create sample indices.\n",
    "\n",
    "        Args:\n",
    "            sequence_length (int): The sequence length.\n",
    "            episode_lengths (list[int]): The lengths of the episodes.\n",
    "        \"\"\"\n",
    "\n",
    "        indices = []\n",
    "        current_index = 0\n",
    "\n",
    "        for episode_length in self.episode_lengths:\n",
    "            for i in range(episode_length - sequence_length + 1):\n",
    "                buffer_start_idx = current_index + i\n",
    "                buffer_end_idx = current_index + i + sequence_length\n",
    "                indices.append((buffer_start_idx, buffer_end_idx))\n",
    "\n",
    "            current_index += episode_length\n",
    "\n",
    "        return np.array(indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the item at the given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index.\n",
    "        \"\"\"\n",
    "\n",
    "        buffer_start_idx, buffer_end_idx = self.indices[idx]\n",
    "\n",
    "        # get the observation and prediction data\n",
    "        obs_data = self.data.iloc[buffer_start_idx:buffer_start_idx + self.obs_horizon].values\n",
    "        # for prediction data, only fetch the last 4 values\n",
    "        # these values correspond to the instructor joint position data\n",
    "        pred_data = self.data.iloc[buffer_start_idx + self.obs_horizon:buffer_end_idx, -4:].values\n",
    "\n",
    "        return obs_data, pred_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
