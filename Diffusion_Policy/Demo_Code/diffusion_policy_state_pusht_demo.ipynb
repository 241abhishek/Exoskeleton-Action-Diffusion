{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QwO2gAgiJS2",
        "outputId": "acec0463-c03f-4359-9680-6ebbc99e4267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n",
            "Requirement already satisfied: torch==1.13.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (1.13.1)\n",
            "Requirement already satisfied: torchvision==0.14.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.14.1)\n",
            "Requirement already satisfied: diffusers==0.18.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.18.2)\n",
            "Requirement already satisfied: scikit-image==0.19.3 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.19.3)\n",
            "Requirement already satisfied: scikit-video==1.1.11 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (1.1.11)\n",
            "Requirement already satisfied: zarr==2.12.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (2.12.0)\n",
            "Requirement already satisfied: numcodecs==0.10.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.10.2)\n",
            "Requirement already satisfied: pygame==2.1.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (2.1.2)\n",
            "Requirement already satisfied: pymunk==6.2.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (6.2.1)\n",
            "Requirement already satisfied: gym==0.26.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (0.26.2)\n",
            "Requirement already satisfied: shapely==1.8.4 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (1.8.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: typing-extensions in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torch==1.13.1) (11.10.3.66)\n",
            "Requirement already satisfied: requests in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torchvision==0.14.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torchvision==0.14.1) (10.3.0)\n",
            "Requirement already satisfied: numpy in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from torchvision==0.14.1) (1.26.4)\n",
            "Requirement already satisfied: importlib-metadata in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (7.1.0)\n",
            "Requirement already satisfied: filelock in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (0.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from diffusers==0.18.2) (2024.5.15)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (1.6.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (2.34.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (2024.6.18)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (24.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from scikit-image==0.19.3) (1.13.1)\n",
            "Requirement already satisfied: fasteners in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from zarr==2.12.0) (0.19)\n",
            "Requirement already satisfied: asciitree in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from zarr==2.12.0) (0.3.3)\n",
            "Requirement already satisfied: entrypoints in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from numcodecs==0.10.2) (0.4)\n",
            "Requirement already satisfied: cffi>=1.15.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from pymunk==6.2.1) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from gym==0.26.2) (3.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from gym==0.26.2) (0.0.8)\n",
            "Requirement already satisfied: wheel in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.43.0)\n",
            "Requirement already satisfied: setuptools in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (59.6.0)\n",
            "Requirement already satisfied: pycparser in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from cffi>=1.15.0->pymunk==6.2.1) (2.22)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.18.2) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.18.2) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.18.2) (2024.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.18.2) (3.19.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (2024.6.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abhi2001/SRA/venv/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (2.2.2)\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Installing pip packages**\n",
        "#@markdown - Diffusion Model: [PyTorch](https://pytorch.org) & [HuggingFace diffusers](https://huggingface.co/docs/diffusers/index)\n",
        "#@markdown - Dataset Loading: [Zarr](https://zarr.readthedocs.io/en/stable/) & numcodecs\n",
        "#@markdown - Push-T Env: gym, pygame, pymunk & shapely\n",
        "!python --version\n",
        "!pip3 install torch==1.13.1 torchvision==0.14.1 diffusers==0.18.2 \\\n",
        "scikit-image==0.19.3 scikit-video==1.1.11 zarr==2.12.0 numcodecs==0.10.2 \\\n",
        "pygame==2.1.2 pymunk==6.2.1 gym==0.26.2 shapely==1.8.4 \\\n",
        "# &> /dev/null # mute output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "49d5ffd9eb81491f95df70e66c0c94e4",
            "9a3d8fbcc3e548e1a56d25c10b321e6a",
            "6cf470f12c174e94b0b058cfba9b5fb2",
            "9b6de90b3dbc4877966b2d5233189866",
            "4b3aeac3e8e74b8f8dab0dc9ad0b7c94",
            "ac6375a33ca84241b50638edb6321112",
            "583a530a9c0442f2b762b281caa4836d",
            "c7d2c3f8b3714a0d911a132c74589ce1",
            "03bbeb04a4c44206b1671e69864e69c7",
            "b2331069d969430b87c47e6f11fb2a9e",
            "c8c282ba14c14da28ba421abc7119cf9"
          ]
        },
        "id": "VrX4VTl5pYNq",
        "outputId": "1a01b12b-0e61-4f38-bb81-f72591e267da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/abhi2001/SRA/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Imports**\n",
        "# diffusion policy import\n",
        "from typing import Tuple, Sequence, Dict, Union, Optional\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "import zarr\n",
        "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
        "from diffusers.training_utils import EMAModel\n",
        "from diffusers.optimization import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# env import\n",
        "import gym\n",
        "from gym import spaces\n",
        "import pygame\n",
        "import pymunk\n",
        "import pymunk.pygame_util\n",
        "from pymunk.space_debug_draw_options import SpaceDebugColor\n",
        "from pymunk.vec2d import Vec2d\n",
        "import shapely.geometry as sg\n",
        "import cv2\n",
        "import skimage.transform as st\n",
        "from skvideo.io import vwrite\n",
        "from IPython.display import Video\n",
        "import gdown\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L5E-nR6ornyg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Environment**\n",
        "#@markdown Defines a PyMunk-based Push-T environment `PushTEnv`.\n",
        "#@markdown\n",
        "#@markdown **Goal**: push the gray T-block into the green area.\n",
        "#@markdown\n",
        "#@markdown Adapted from [Implicit Behavior Cloning](https://implicitbc.github.io/)\n",
        "\n",
        "\n",
        "positive_y_is_up: bool = False\n",
        "\"\"\"Make increasing values of y point upwards.\n",
        "\n",
        "When True::\n",
        "\n",
        "    y\n",
        "    ^\n",
        "    |      . (3, 3)\n",
        "    |\n",
        "    |   . (2, 2)\n",
        "    |\n",
        "    +------ > x\n",
        "\n",
        "When False::\n",
        "\n",
        "    +------ > x\n",
        "    |\n",
        "    |   . (2, 2)\n",
        "    |\n",
        "    |      . (3, 3)\n",
        "    v\n",
        "    y\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def to_pygame(p: Tuple[float, float], surface: pygame.Surface) -> Tuple[int, int]:\n",
        "    \"\"\"Convenience method to convert pymunk coordinates to pygame surface\n",
        "    local coordinates.\n",
        "\n",
        "    Note that in case positive_y_is_up is False, this function wont actually do\n",
        "    anything except converting the point to integers.\n",
        "    \"\"\"\n",
        "    if positive_y_is_up:\n",
        "        return round(p[0]), surface.get_height() - round(p[1])\n",
        "    else:\n",
        "        return round(p[0]), round(p[1])\n",
        "\n",
        "def light_color(color: SpaceDebugColor):\n",
        "    color = np.minimum(1.2 * np.float32([color.r, color.g, color.b, color.a]), np.float32([255]))\n",
        "    color = SpaceDebugColor(r=color[0], g=color[1], b=color[2], a=color[3])\n",
        "    return color\n",
        "\n",
        "class DrawOptions(pymunk.SpaceDebugDrawOptions):\n",
        "    def __init__(self, surface: pygame.Surface) -> None:\n",
        "        \"\"\"Draw a pymunk.Space on a pygame.Surface object.\n",
        "\n",
        "        Typical usage::\n",
        "\n",
        "        >>> import pymunk\n",
        "        >>> surface = pygame.Surface((10,10))\n",
        "        >>> space = pymunk.Space()\n",
        "        >>> options = pymunk.pygame_util.DrawOptions(surface)\n",
        "        >>> space.debug_draw(options)\n",
        "\n",
        "        You can control the color of a shape by setting shape.color to the color\n",
        "        you want it drawn in::\n",
        "\n",
        "        >>> c = pymunk.Circle(None, 10)\n",
        "        >>> c.color = pygame.Color(\"pink\")\n",
        "\n",
        "        See pygame_util.demo.py for a full example\n",
        "\n",
        "        Since pygame uses a coordiante system where y points down (in contrast\n",
        "        to many other cases), you either have to make the physics simulation\n",
        "        with Pymunk also behave in that way, or flip everything when you draw.\n",
        "\n",
        "        The easiest is probably to just make the simulation behave the same\n",
        "        way as Pygame does. In that way all coordinates used are in the same\n",
        "        orientation and easy to reason about::\n",
        "\n",
        "        >>> space = pymunk.Space()\n",
        "        >>> space.gravity = (0, -1000)\n",
        "        >>> body = pymunk.Body()\n",
        "        >>> body.position = (0, 0) # will be positioned in the top left corner\n",
        "        >>> space.debug_draw(options)\n",
        "\n",
        "        To flip the drawing its possible to set the module property\n",
        "        :py:data:`positive_y_is_up` to True. Then the pygame drawing will flip\n",
        "        the simulation upside down before drawing::\n",
        "\n",
        "        >>> positive_y_is_up = True\n",
        "        >>> body = pymunk.Body()\n",
        "        >>> body.position = (0, 0)\n",
        "        >>> # Body will be position in bottom left corner\n",
        "\n",
        "        :Parameters:\n",
        "                surface : pygame.Surface\n",
        "                    Surface that the objects will be drawn on\n",
        "        \"\"\"\n",
        "        self.surface = surface\n",
        "        super(DrawOptions, self).__init__()\n",
        "\n",
        "    def draw_circle(\n",
        "        self,\n",
        "        pos: Vec2d,\n",
        "        angle: float,\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        p = to_pygame(pos, self.surface)\n",
        "\n",
        "        pygame.draw.circle(self.surface, fill_color.as_int(), p, round(radius), 0)\n",
        "        pygame.draw.circle(self.surface, light_color(fill_color).as_int(), p, round(radius-4), 0)\n",
        "\n",
        "        circle_edge = pos + Vec2d(radius, 0).rotated(angle)\n",
        "        p2 = to_pygame(circle_edge, self.surface)\n",
        "        line_r = 2 if radius > 20 else 1\n",
        "        # pygame.draw.lines(self.surface, outline_color.as_int(), False, [p, p2], line_r)\n",
        "\n",
        "    def draw_segment(self, a: Vec2d, b: Vec2d, color: SpaceDebugColor) -> None:\n",
        "        p1 = to_pygame(a, self.surface)\n",
        "        p2 = to_pygame(b, self.surface)\n",
        "\n",
        "        pygame.draw.aalines(self.surface, color.as_int(), False, [p1, p2])\n",
        "\n",
        "    def draw_fat_segment(\n",
        "        self,\n",
        "        a: Tuple[float, float],\n",
        "        b: Tuple[float, float],\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        p1 = to_pygame(a, self.surface)\n",
        "        p2 = to_pygame(b, self.surface)\n",
        "\n",
        "        r = round(max(1, radius * 2))\n",
        "        pygame.draw.lines(self.surface, fill_color.as_int(), False, [p1, p2], r)\n",
        "        if r > 2:\n",
        "            orthog = [abs(p2[1] - p1[1]), abs(p2[0] - p1[0])]\n",
        "            if orthog[0] == 0 and orthog[1] == 0:\n",
        "                return\n",
        "            scale = radius / (orthog[0] * orthog[0] + orthog[1] * orthog[1]) ** 0.5\n",
        "            orthog[0] = round(orthog[0] * scale)\n",
        "            orthog[1] = round(orthog[1] * scale)\n",
        "            points = [\n",
        "                (p1[0] - orthog[0], p1[1] - orthog[1]),\n",
        "                (p1[0] + orthog[0], p1[1] + orthog[1]),\n",
        "                (p2[0] + orthog[0], p2[1] + orthog[1]),\n",
        "                (p2[0] - orthog[0], p2[1] - orthog[1]),\n",
        "            ]\n",
        "            pygame.draw.polygon(self.surface, fill_color.as_int(), points)\n",
        "            pygame.draw.circle(\n",
        "                self.surface,\n",
        "                fill_color.as_int(),\n",
        "                (round(p1[0]), round(p1[1])),\n",
        "                round(radius),\n",
        "            )\n",
        "            pygame.draw.circle(\n",
        "                self.surface,\n",
        "                fill_color.as_int(),\n",
        "                (round(p2[0]), round(p2[1])),\n",
        "                round(radius),\n",
        "            )\n",
        "\n",
        "    def draw_polygon(\n",
        "        self,\n",
        "        verts: Sequence[Tuple[float, float]],\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        ps = [to_pygame(v, self.surface) for v in verts]\n",
        "        ps += [ps[0]]\n",
        "\n",
        "        radius = 2\n",
        "        pygame.draw.polygon(self.surface, light_color(fill_color).as_int(), ps)\n",
        "\n",
        "        if radius > 0:\n",
        "            for i in range(len(verts)):\n",
        "                a = verts[i]\n",
        "                b = verts[(i + 1) % len(verts)]\n",
        "                self.draw_fat_segment(a, b, radius, fill_color, fill_color)\n",
        "\n",
        "    def draw_dot(\n",
        "        self, size: float, pos: Tuple[float, float], color: SpaceDebugColor\n",
        "    ) -> None:\n",
        "        p = to_pygame(pos, self.surface)\n",
        "        pygame.draw.circle(self.surface, color.as_int(), p, round(size), 0)\n",
        "\n",
        "\n",
        "def pymunk_to_shapely(body, shapes):\n",
        "    geoms = list()\n",
        "    for shape in shapes:\n",
        "        if isinstance(shape, pymunk.shapes.Poly):\n",
        "            verts = [body.local_to_world(v) for v in shape.get_vertices()]\n",
        "            verts += [verts[0]]\n",
        "            geoms.append(sg.Polygon(verts))\n",
        "        else:\n",
        "            raise RuntimeError(f'Unsupported shape type {type(shape)}')\n",
        "    geom = sg.MultiPolygon(geoms)\n",
        "    return geom\n",
        "\n",
        "# env\n",
        "class PushTEnv(gym.Env):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
        "    reward_range = (0., 1.)\n",
        "\n",
        "    def __init__(self,\n",
        "            legacy=False,\n",
        "            block_cog=None, damping=None,\n",
        "            render_action=True,\n",
        "            render_size=96,\n",
        "            reset_to_state=None\n",
        "        ):\n",
        "        self._seed = None\n",
        "        self.seed()\n",
        "        self.window_size = ws = 512  # The size of the PyGame window\n",
        "        self.render_size = render_size\n",
        "        self.sim_hz = 100\n",
        "        # Local controller params.\n",
        "        self.k_p, self.k_v = 100, 20    # PD control.z\n",
        "        self.control_hz = self.metadata['video.frames_per_second']\n",
        "        # legcay set_state for data compatiblity\n",
        "        self.legacy = legacy\n",
        "\n",
        "        # agent_pos, block_pos, block_angle\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0,0,0,0,0], dtype=np.float64),\n",
        "            high=np.array([ws,ws,ws,ws,np.pi*2], dtype=np.float64),\n",
        "            shape=(5,),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "\n",
        "        # positional goal for agent\n",
        "        self.action_space = spaces.Box(\n",
        "            low=np.array([0,0], dtype=np.float64),\n",
        "            high=np.array([ws,ws], dtype=np.float64),\n",
        "            shape=(2,),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "\n",
        "        self.block_cog = block_cog\n",
        "        self.damping = damping\n",
        "        self.render_action = render_action\n",
        "\n",
        "        \"\"\"\n",
        "        If human-rendering is used, `self.window` will be a reference\n",
        "        to the window that we draw to. `self.clock` will be a clock that is used\n",
        "        to ensure that the environment is rendered at the correct framerate in\n",
        "        human-mode. They will remain `None` until human-mode is used for the\n",
        "        first time.\n",
        "        \"\"\"\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "        self.screen = None\n",
        "\n",
        "        self.space = None\n",
        "        self.teleop = None\n",
        "        self.render_buffer = None\n",
        "        self.latest_action = None\n",
        "        self.reset_to_state = reset_to_state\n",
        "\n",
        "    def reset(self):\n",
        "        seed = self._seed\n",
        "        self._setup()\n",
        "        if self.block_cog is not None:\n",
        "            self.block.center_of_gravity = self.block_cog\n",
        "        if self.damping is not None:\n",
        "            self.space.damping = self.damping\n",
        "\n",
        "        # use legacy RandomState for compatiblity\n",
        "        state = self.reset_to_state\n",
        "        if state is None:\n",
        "            rs = np.random.RandomState(seed=seed)\n",
        "            state = np.array([\n",
        "                rs.randint(50, 450), rs.randint(50, 450),\n",
        "                rs.randint(100, 400), rs.randint(100, 400),\n",
        "                rs.randn() * 2 * np.pi - np.pi\n",
        "                ])\n",
        "        self._set_state(state)\n",
        "\n",
        "        obs = self._get_obs()\n",
        "        info = self._get_info()\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, action):\n",
        "        dt = 1.0 / self.sim_hz\n",
        "        self.n_contact_points = 0\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        if action is not None:\n",
        "            self.latest_action = action\n",
        "            for i in range(n_steps):\n",
        "                # Step PD control.\n",
        "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
        "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (Vec2d(0, 0) - self.agent.velocity)\n",
        "                self.agent.velocity += acceleration * dt\n",
        "\n",
        "                # Step physics.\n",
        "                self.space.step(dt)\n",
        "\n",
        "        # compute reward\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
        "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
        "\n",
        "        intersection_area = goal_geom.intersection(block_geom).area\n",
        "        goal_area = goal_geom.area\n",
        "        coverage = intersection_area / goal_area\n",
        "        reward = np.clip(coverage / self.success_threshold, 0, 1)\n",
        "        done = coverage > self.success_threshold\n",
        "        terminated = done\n",
        "        truncated = done\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def render(self, mode):\n",
        "        return self._render_frame(mode)\n",
        "\n",
        "    def teleop_agent(self):\n",
        "        TeleopAgent = collections.namedtuple('TeleopAgent', ['act'])\n",
        "        def act(obs):\n",
        "            act = None\n",
        "            mouse_position = pymunk.pygame_util.from_pygame(Vec2d(*pygame.mouse.get_pos()), self.screen)\n",
        "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
        "                self.teleop = True\n",
        "                act = mouse_position\n",
        "            return act\n",
        "        return TeleopAgent(act)\n",
        "\n",
        "    def _get_obs(self):\n",
        "        obs = np.array(\n",
        "            tuple(self.agent.position) \\\n",
        "            + tuple(self.block.position) \\\n",
        "            + (self.block.angle % (2 * np.pi),))\n",
        "        return obs\n",
        "\n",
        "    def _get_goal_pose_body(self, pose):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        # preserving the legacy assignment order for compatibility\n",
        "        # the order here dosn't matter somehow, maybe because CoM is aligned with body origin\n",
        "        body.position = pose[:2].tolist()\n",
        "        body.angle = pose[2]\n",
        "        return body\n",
        "\n",
        "    def _get_info(self):\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
        "        info = {\n",
        "            'pos_agent': np.array(self.agent.position),\n",
        "            'vel_agent': np.array(self.agent.velocity),\n",
        "            'block_pose': np.array(list(self.block.position) + [self.block.angle]),\n",
        "            'goal_pose': self.goal_pose,\n",
        "            'n_contacts': n_contact_points_per_step}\n",
        "        return info\n",
        "\n",
        "    def _render_frame(self, mode):\n",
        "\n",
        "        if self.window is None and mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
        "        if self.clock is None and mode == \"human\":\n",
        "            self.clock = pygame.time.Clock()\n",
        "\n",
        "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
        "        canvas.fill((255, 255, 255))\n",
        "        self.screen = canvas\n",
        "\n",
        "        draw_options = DrawOptions(canvas)\n",
        "\n",
        "        # Draw goal pose.\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        for shape in self.block.shapes:\n",
        "            goal_points = [pymunk.pygame_util.to_pygame(goal_body.local_to_world(v), draw_options.surface) for v in shape.get_vertices()]\n",
        "            goal_points += [goal_points[0]]\n",
        "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
        "\n",
        "        # Draw agent and block.\n",
        "        self.space.debug_draw(draw_options)\n",
        "\n",
        "        if mode == \"human\":\n",
        "            # The following line copies our drawings from `canvas` to the visible window\n",
        "            self.window.blit(canvas, canvas.get_rect())\n",
        "            pygame.event.pump()\n",
        "            pygame.display.update()\n",
        "\n",
        "            # the clock is aleady ticked during in step for \"human\"\n",
        "\n",
        "\n",
        "        img = np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
        "            )\n",
        "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
        "        if self.render_action:\n",
        "            if self.render_action and (self.latest_action is not None):\n",
        "                action = np.array(self.latest_action)\n",
        "                coord = (action / 512 * 96).astype(np.int32)\n",
        "                marker_size = int(8/96*self.render_size)\n",
        "                thickness = int(1/96*self.render_size)\n",
        "                cv2.drawMarker(img, coord,\n",
        "                    color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
        "                    markerSize=marker_size, thickness=thickness)\n",
        "        return img\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        if self.window is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        if seed is None:\n",
        "            seed = np.random.randint(0,25536)\n",
        "        self._seed = seed\n",
        "        self.np_random = np.random.default_rng(seed)\n",
        "\n",
        "    def _handle_collision(self, arbiter, space, data):\n",
        "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
        "\n",
        "    def _set_state(self, state):\n",
        "        if isinstance(state, np.ndarray):\n",
        "            state = state.tolist()\n",
        "        pos_agent = state[:2]\n",
        "        pos_block = state[2:4]\n",
        "        rot_block = state[4]\n",
        "        self.agent.position = pos_agent\n",
        "        # setting angle rotates with respect to center of mass\n",
        "        # therefore will modify the geometric position\n",
        "        # if not the same as CoM\n",
        "        # therefore should be modified first.\n",
        "        if self.legacy:\n",
        "            # for compatiblity with legacy data\n",
        "            self.block.position = pos_block\n",
        "            self.block.angle = rot_block\n",
        "        else:\n",
        "            self.block.angle = rot_block\n",
        "            self.block.position = pos_block\n",
        "\n",
        "        # Run physics to take effect\n",
        "        self.space.step(1.0 / self.sim_hz)\n",
        "\n",
        "    def _set_state_local(self, state_local):\n",
        "        agent_pos_local = state_local[:2]\n",
        "        block_pose_local = state_local[2:]\n",
        "        tf_img_obj = st.AffineTransform(\n",
        "            translation=self.goal_pose[:2],\n",
        "            rotation=self.goal_pose[2])\n",
        "        tf_obj_new = st.AffineTransform(\n",
        "            translation=block_pose_local[:2],\n",
        "            rotation=block_pose_local[2]\n",
        "        )\n",
        "        tf_img_new = st.AffineTransform(\n",
        "            matrix=tf_img_obj.params @ tf_obj_new.params\n",
        "        )\n",
        "        agent_pos_new = tf_img_new(agent_pos_local)\n",
        "        new_state = np.array(\n",
        "            list(agent_pos_new[0]) + list(tf_img_new.translation) \\\n",
        "                + [tf_img_new.rotation])\n",
        "        self._set_state(new_state)\n",
        "        return new_state\n",
        "\n",
        "    def _setup(self):\n",
        "        self.space = pymunk.Space()\n",
        "        self.space.gravity = 0, 0\n",
        "        self.space.damping = 0\n",
        "        self.teleop = False\n",
        "        self.render_buffer = list()\n",
        "\n",
        "        # Add walls.\n",
        "        walls = [\n",
        "            self._add_segment((5, 506), (5, 5), 2),\n",
        "            self._add_segment((5, 5), (506, 5), 2),\n",
        "            self._add_segment((506, 5), (506, 506), 2),\n",
        "            self._add_segment((5, 506), (506, 506), 2)\n",
        "        ]\n",
        "        self.space.add(*walls)\n",
        "\n",
        "        # Add agent, block, and goal zone.\n",
        "        self.agent = self.add_circle((256, 400), 15)\n",
        "        self.block = self.add_tee((256, 300), 0)\n",
        "        self.goal_color = pygame.Color('LightGreen')\n",
        "        self.goal_pose = np.array([256,256,np.pi/4])  # x, y, theta (in radians)\n",
        "\n",
        "        # Add collision handeling\n",
        "        self.collision_handeler = self.space.add_collision_handler(0, 0)\n",
        "        self.collision_handeler.post_solve = self._handle_collision\n",
        "        self.n_contact_points = 0\n",
        "\n",
        "        self.max_score = 50 * 100\n",
        "        self.success_threshold = 0.95    # 95% coverage.\n",
        "\n",
        "    def _add_segment(self, a, b, radius):\n",
        "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
        "        shape.color = pygame.Color('LightGray')    # https://htmlcolorcodes.com/color-names\n",
        "        return shape\n",
        "\n",
        "    def add_circle(self, position, radius):\n",
        "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
        "        body.position = position\n",
        "        body.friction = 1\n",
        "        shape = pymunk.Circle(body, radius)\n",
        "        shape.color = pygame.Color('RoyalBlue')\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_box(self, position, height, width):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        body.position = position\n",
        "        shape = pymunk.Poly.create_box(body, (height, width))\n",
        "        shape.color = pygame.Color('LightSlateGray')\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_tee(self, position, angle, scale=30, color='LightSlateGray', mask=pymunk.ShapeFilter.ALL_MASKS()):\n",
        "        mass = 1\n",
        "        length = 4\n",
        "        vertices1 = [(-length*scale/2, scale),\n",
        "                                 ( length*scale/2, scale),\n",
        "                                 ( length*scale/2, 0),\n",
        "                                 (-length*scale/2, 0)]\n",
        "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        vertices2 = [(-scale/2, scale),\n",
        "                                 (-scale/2, length*scale),\n",
        "                                 ( scale/2, length*scale),\n",
        "                                 ( scale/2, scale)]\n",
        "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
        "        shape1 = pymunk.Poly(body, vertices1)\n",
        "        shape2 = pymunk.Poly(body, vertices2)\n",
        "        shape1.color = pygame.Color(color)\n",
        "        shape2.color = pygame.Color(color)\n",
        "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        body.center_of_gravity = (shape1.center_of_gravity + shape2.center_of_gravity) / 2\n",
        "        body.position = position\n",
        "        body.angle = angle\n",
        "        body.friction = 1\n",
        "        self.space.add(body, shape1, shape2)\n",
        "        return body\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OknH8Qfqrtc9",
        "outputId": "7563449e-9549-4de2-e049-bde843e76fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obs:  array([206.0037, 201.2372, 292.    , 351.    ,   2.9196])\n",
            "Obs:        [agent_x,  agent_y,  block_x,  block_y,    block_angle]\n",
            "Action:  array([370.3794, 392.3724])\n",
            "Action:   [target_agent_x, target_agent_y]\n"
          ]
        }
      ],
      "source": [
        "# from huggingface_hub.utils import IGNORE_GIT_FOLDER_PATTERNS\n",
        "#@markdown ### **Env Demo**\n",
        "#@markdown Standard Gym Env (0.21.0 API)\n",
        "\n",
        "# 0. create env object\n",
        "env = PushTEnv()\n",
        "\n",
        "# 1. seed env for initial state.\n",
        "# Seed 0-200 are used for the demonstration dataset.\n",
        "env.seed(1000)\n",
        "\n",
        "# 2. must reset before use\n",
        "# obs, IGNORE_GIT_FOLDER_PATTERNS = env.reset()\n",
        "obs, IGNORE_GIT_FOLDER_PATTERNS = env.reset()\n",
        "\n",
        "# 3. 2D positional action space [0,512]\n",
        "action = env.action_space.sample()\n",
        "\n",
        "# 4. Standard gym step method\n",
        "obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "# prints and explains each dimension of the observation and action vectors\n",
        "with np.printoptions(precision=4, suppress=True, threshold=5):\n",
        "    print(\"Obs: \", repr(obs))\n",
        "    print(\"Obs:        [agent_x,  agent_y,  block_x,  block_y,    block_angle]\")\n",
        "    print(\"Action: \", repr(action))\n",
        "    print(\"Action:   [target_agent_x, target_agent_y]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "vHepJOFBucwg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Dataset**\n",
        "#@markdown\n",
        "#@markdown Defines `PushTStateDataset` and helper functions\n",
        "#@markdown\n",
        "#@markdown The dataset class\n",
        "#@markdown - Load data (obs, action) from a zarr storage\n",
        "#@markdown - Normalizes each dimension of obs and action to [-1,1]\n",
        "#@markdown - Returns\n",
        "#@markdown  - All possible segments with length `pred_horizon`\n",
        "#@markdown  - Pads the beginning and the end of each episode with repetition\n",
        "#@markdown  - key `obs`: shape (obs_horizon, obs_dim)\n",
        "#@markdown  - key `action`: shape (pred_horizon, action_dim)\n",
        "\n",
        "def create_sample_indices(\n",
        "        episode_ends:np.ndarray, sequence_length:int,\n",
        "        pad_before: int=0, pad_after: int=0):\n",
        "    indices = list()\n",
        "    for i in range(len(episode_ends)):\n",
        "        start_idx = 0\n",
        "        if i > 0:\n",
        "            start_idx = episode_ends[i-1]\n",
        "        end_idx = episode_ends[i]\n",
        "        episode_length = end_idx - start_idx\n",
        "\n",
        "        min_start = -pad_before\n",
        "        max_start = episode_length - sequence_length + pad_after\n",
        "\n",
        "        # range stops one idx before end\n",
        "        for idx in range(min_start, max_start+1):\n",
        "            buffer_start_idx = max(idx, 0) + start_idx\n",
        "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
        "            start_offset = buffer_start_idx - (idx+start_idx)\n",
        "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
        "            sample_start_idx = 0 + start_offset\n",
        "            sample_end_idx = sequence_length - end_offset\n",
        "            indices.append([\n",
        "                buffer_start_idx, buffer_end_idx,\n",
        "                sample_start_idx, sample_end_idx])\n",
        "    indices = np.array(indices)\n",
        "    return indices\n",
        "\n",
        "\n",
        "def sample_sequence(train_data, sequence_length,\n",
        "                    buffer_start_idx, buffer_end_idx,\n",
        "                    sample_start_idx, sample_end_idx):\n",
        "    result = dict()\n",
        "    for key, input_arr in train_data.items():\n",
        "        sample = input_arr[buffer_start_idx:buffer_end_idx]\n",
        "        data = sample\n",
        "        if (sample_start_idx > 0) or (sample_end_idx < sequence_length):\n",
        "            data = np.zeros(\n",
        "                shape=(sequence_length,) + input_arr.shape[1:],\n",
        "                dtype=input_arr.dtype)\n",
        "            if sample_start_idx > 0:\n",
        "                data[:sample_start_idx] = sample[0]\n",
        "            if sample_end_idx < sequence_length:\n",
        "                data[sample_end_idx:] = sample[-1]\n",
        "            data[sample_start_idx:sample_end_idx] = sample\n",
        "        result[key] = data\n",
        "    return result\n",
        "\n",
        "# normalize data\n",
        "def get_data_stats(data):\n",
        "    data = data.reshape(-1,data.shape[-1])\n",
        "    stats = {\n",
        "        'min': np.min(data, axis=0),\n",
        "        'max': np.max(data, axis=0)\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "def normalize_data(data, stats):\n",
        "    # nomalize to [0,1]\n",
        "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
        "    # normalize to [-1, 1]\n",
        "    ndata = ndata * 2 - 1\n",
        "    return ndata\n",
        "\n",
        "def unnormalize_data(ndata, stats):\n",
        "    ndata = (ndata + 1) / 2\n",
        "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
        "    return data\n",
        "\n",
        "# dataset\n",
        "class PushTStateDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset_path,\n",
        "                 pred_horizon, obs_horizon, action_horizon):\n",
        "\n",
        "        # read from zarr dataset\n",
        "        dataset_root = zarr.open(dataset_path, 'r')\n",
        "        # All demonstration episodes are concatinated in the first dimension N\n",
        "        train_data = {\n",
        "            # (N, action_dim)\n",
        "            'action': dataset_root['data']['action'][:],\n",
        "            # (N, obs_dim)\n",
        "            'obs': dataset_root['data']['state'][:]\n",
        "        }\n",
        "        # Marks one-past the last index for each episode\n",
        "        episode_ends = dataset_root['meta']['episode_ends'][:]\n",
        "\n",
        "        # compute start and end of each state-action sequence\n",
        "        # also handles padding\n",
        "        indices = create_sample_indices(\n",
        "            episode_ends=episode_ends,\n",
        "            sequence_length=pred_horizon,\n",
        "            # add padding such that each timestep in the dataset are seen\n",
        "            pad_before=obs_horizon-1,\n",
        "            pad_after=action_horizon-1)\n",
        "\n",
        "        # compute statistics and normalized data to [-1,1]\n",
        "        stats = dict()\n",
        "        normalized_train_data = dict()\n",
        "        for key, data in train_data.items():\n",
        "            stats[key] = get_data_stats(data)\n",
        "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
        "\n",
        "        self.indices = indices\n",
        "        self.stats = stats\n",
        "        self.normalized_train_data = normalized_train_data\n",
        "        self.pred_horizon = pred_horizon\n",
        "        self.action_horizon = action_horizon\n",
        "        self.obs_horizon = obs_horizon\n",
        "\n",
        "    def __len__(self):\n",
        "        # all possible segments of the dataset\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get the start/end indices for this datapoint\n",
        "        buffer_start_idx, buffer_end_idx, \\\n",
        "            sample_start_idx, sample_end_idx = self.indices[idx]\n",
        "\n",
        "        # get nomralized data using these indices\n",
        "        nsample = sample_sequence(\n",
        "            train_data=self.normalized_train_data,\n",
        "            sequence_length=self.pred_horizon,\n",
        "            buffer_start_idx=buffer_start_idx,\n",
        "            buffer_end_idx=buffer_end_idx,\n",
        "            sample_start_idx=sample_start_idx,\n",
        "            sample_end_idx=sample_end_idx\n",
        "        )\n",
        "\n",
        "        # discard unused observations\n",
        "        nsample['obs'] = nsample['obs'][:self.obs_horizon,:]\n",
        "        return nsample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZiHF3lzvB6k",
        "outputId": "474315be-970f-4a47-ca7e-d27d92a1711f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch['obs'].shape: torch.Size([256, 2, 5])\n",
            "batch['action'].shape torch.Size([256, 16, 2])\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Dataset Demo**\n",
        "\n",
        "# download demonstration data from Google Drive\n",
        "dataset_path = \"pusht_cchi_v7_replay.zarr.zip\"\n",
        "if not os.path.isfile(dataset_path):\n",
        "    id = \"1KY1InLurpMvJDRb14L9NlXT_fEsCvVUq&confirm=t\"\n",
        "    gdown.download(id=id, output=dataset_path, quiet=False)\n",
        "\n",
        "# parameters\n",
        "pred_horizon = 16\n",
        "obs_horizon = 2\n",
        "action_horizon = 8\n",
        "#|o|o|                             observations: 2\n",
        "#| |a|a|a|a|a|a|a|a|               actions executed: 8\n",
        "#|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
        "\n",
        "# create dataset from file\n",
        "dataset = PushTStateDataset(\n",
        "    dataset_path=dataset_path,\n",
        "    pred_horizon=pred_horizon,\n",
        "    obs_horizon=obs_horizon,\n",
        "    action_horizon=action_horizon\n",
        ")\n",
        "# save training data statistics (min, max) for each dim\n",
        "stats = dataset.stats\n",
        "\n",
        "# create dataloader\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    num_workers=1,\n",
        "    shuffle=True,\n",
        "    # accelerate cpu-gpu transfer\n",
        "    pin_memory=True,\n",
        "    # don't kill worker process afte each epoch\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "# visualize data in batch\n",
        "batch = next(iter(dataloader))\n",
        "print(\"batch['obs'].shape:\", batch['obs'].shape)\n",
        "print(\"batch['action'].shape\", batch['action'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "X-XRB_g3vsgf"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Network**\n",
        "#@markdown\n",
        "#@markdown Defines a 1D UNet architecture `ConditionalUnet1D`\n",
        "#@markdown as the noies prediction network\n",
        "#@markdown\n",
        "#@markdown Components\n",
        "#@markdown - `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
        "#@markdown - `Downsample1d` Strided convolution to reduce temporal resolution\n",
        "#@markdown - `Upsample1d` Transposed convolution to increase temporal resolution\n",
        "#@markdown - `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
        "#@markdown - `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
        "#@markdown `x` is passed through 2 `Conv1dBlock` stacked together with residual connection.\n",
        "#@markdown `cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class Downsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Upsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Conv1dBlock(nn.Module):\n",
        "    '''\n",
        "        Conv1d --> GroupNorm --> Mish\n",
        "    '''\n",
        "\n",
        "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
        "            nn.GroupNorm(n_groups, out_channels),\n",
        "            nn.Mish(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class ConditionalResidualBlock1D(nn.Module):\n",
        "    def __init__(self,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            cond_dim,\n",
        "            kernel_size=3,\n",
        "            n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "        ])\n",
        "\n",
        "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
        "        # predicts per-channel scale and bias\n",
        "        cond_channels = out_channels * 2\n",
        "        self.out_channels = out_channels\n",
        "        self.cond_encoder = nn.Sequential(\n",
        "            nn.Mish(),\n",
        "            nn.Linear(cond_dim, cond_channels),\n",
        "            nn.Unflatten(-1, (-1, 1))\n",
        "        )\n",
        "\n",
        "        # make sure dimensions compatible\n",
        "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
        "            if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        '''\n",
        "            x : [ batch_size x in_channels x horizon ]\n",
        "            cond : [ batch_size x cond_dim]\n",
        "\n",
        "            returns:\n",
        "            out : [ batch_size x out_channels x horizon ]\n",
        "        '''\n",
        "        out = self.blocks[0](x)\n",
        "        embed = self.cond_encoder(cond)\n",
        "\n",
        "        embed = embed.reshape(\n",
        "            embed.shape[0], 2, self.out_channels, 1)\n",
        "        scale = embed[:,0,...]\n",
        "        bias = embed[:,1,...]\n",
        "        out = scale * out + bias\n",
        "\n",
        "        out = self.blocks[1](out)\n",
        "        out = out + self.residual_conv(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConditionalUnet1D(nn.Module):\n",
        "    def __init__(self,\n",
        "        input_dim,\n",
        "        global_cond_dim,\n",
        "        diffusion_step_embed_dim=256,\n",
        "        down_dims=[256,512,1024],\n",
        "        kernel_size=5,\n",
        "        n_groups=8\n",
        "        ):\n",
        "        \"\"\"\n",
        "        input_dim: Dim of actions.\n",
        "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
        "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
        "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
        "        down_dims: Channel size for each UNet level.\n",
        "          The length of this array determines numebr of levels.\n",
        "        kernel_size: Conv kernel size\n",
        "        n_groups: Number of groups for GroupNorm\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        all_dims = [input_dim] + list(down_dims)\n",
        "        start_dim = down_dims[0]\n",
        "\n",
        "        dsed = diffusion_step_embed_dim\n",
        "        diffusion_step_encoder = nn.Sequential(\n",
        "            SinusoidalPosEmb(dsed),\n",
        "            nn.Linear(dsed, dsed * 4),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(dsed * 4, dsed),\n",
        "        )\n",
        "        cond_dim = dsed + global_cond_dim\n",
        "\n",
        "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
        "        mid_dim = all_dims[-1]\n",
        "        self.mid_modules = nn.ModuleList([\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "        down_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            down_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_out, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out, dim_out, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        up_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            up_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Upsample1d(dim_in) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        final_conv = nn.Sequential(\n",
        "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
        "            nn.Conv1d(start_dim, input_dim, 1),\n",
        "        )\n",
        "\n",
        "        self.diffusion_step_encoder = diffusion_step_encoder\n",
        "        self.up_modules = up_modules\n",
        "        self.down_modules = down_modules\n",
        "        self.final_conv = final_conv\n",
        "\n",
        "        print(\"number of parameters: {:e}\".format(\n",
        "            sum(p.numel() for p in self.parameters()))\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "            sample: torch.Tensor,\n",
        "            timestep: Union[torch.Tensor, float, int],\n",
        "            global_cond=None):\n",
        "        \"\"\"\n",
        "        x: (B,T,input_dim)\n",
        "        timestep: (B,) or int, diffusion step\n",
        "        global_cond: (B,global_cond_dim)\n",
        "        output: (B,T,input_dim)\n",
        "        \"\"\"\n",
        "        # (B,T,C)\n",
        "        sample = sample.moveaxis(-1,-2)\n",
        "        # (B,C,T)\n",
        "\n",
        "        # 1. time\n",
        "        timesteps = timestep\n",
        "        if not torch.is_tensor(timesteps):\n",
        "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
        "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
        "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
        "            timesteps = timesteps[None].to(sample.device)\n",
        "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
        "        timesteps = timesteps.expand(sample.shape[0])\n",
        "\n",
        "        global_feature = self.diffusion_step_encoder(timesteps)\n",
        "\n",
        "        if global_cond is not None:\n",
        "            global_feature = torch.cat([\n",
        "                global_feature, global_cond\n",
        "            ], axis=-1)\n",
        "\n",
        "        x = sample\n",
        "        h = []\n",
        "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        for mid_module in self.mid_modules:\n",
        "            x = mid_module(x, global_feature)\n",
        "\n",
        "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            x = upsample(x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # (B,C,T)\n",
        "        x = x.moveaxis(-1,-2)\n",
        "        # (B,T,C)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4APZkqh336-M",
        "outputId": "51fbbfb0-deaf-48bd-cf4b-dc7f8f4ff246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 6.535322e+07\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Network Demo**\n",
        "\n",
        "# observation and action dimensions corrsponding to\n",
        "# the output of PushTEnv\n",
        "obs_dim = 5\n",
        "action_dim = 2\n",
        "\n",
        "# create network object\n",
        "noise_pred_net = ConditionalUnet1D(\n",
        "    input_dim=action_dim,\n",
        "    global_cond_dim=obs_dim*obs_horizon\n",
        ")\n",
        "\n",
        "# example inputs\n",
        "noised_action = torch.randn((1, pred_horizon, action_dim))\n",
        "obs = torch.zeros((1, obs_horizon, obs_dim))\n",
        "diffusion_iter = torch.zeros((1,))\n",
        "\n",
        "# the noise prediction network\n",
        "# takes noisy action, diffusion iteration and observation as input\n",
        "# predicts the noise added to action\n",
        "noise = noise_pred_net(\n",
        "    sample=noised_action,\n",
        "    timestep=diffusion_iter,\n",
        "    global_cond=obs.flatten(start_dim=1))\n",
        "\n",
        "# illustration of removing noise\n",
        "# the actual noise removal is performed by NoiseScheduler\n",
        "# and is dependent on the diffusion noise schedule\n",
        "denoised_action = noised_action - noise\n",
        "\n",
        "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
        "num_diffusion_iters = 100\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    num_train_timesteps=num_diffusion_iters,\n",
        "    # the choise of beta schedule has big impact on performance\n",
        "    # we found squared cosine works the best\n",
        "    beta_schedule='squaredcos_cap_v2',\n",
        "    # clip output to [-1,1] to improve stability\n",
        "    clip_sample=True,\n",
        "    # our network predicts noise (instead of denoised action)\n",
        "    prediction_type='epsilon'\n",
        ")\n",
        "\n",
        "# device transfer\n",
        "device = torch.device('cuda')\n",
        "_ = noise_pred_net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c29b0972b22d4dc59844ea958abf7bd1",
            "df7b2e7c39944341be1a091331fd7cc6",
            "0d687f5624cb4871ad167ebcbcb4c148",
            "82a5a8a6be3a41209de270d5072838a2",
            "6d4dfa99470e40559bebd6689305f155",
            "0964ed28f2794bdf91e2e2756aae3bc4",
            "1939a1c3cc7a498fa5f05ac737b0af99",
            "116ecf0deb6e44faadb594f2f982c4c2",
            "2db415245cbb44c8ab5c208be328fc16",
            "ed0c7c76b76d40c9b25ca92abb00cf34",
            "3a5463e9f9864ca2b52fe9cd28f4a8b8",
            "5352c2178612408aa84a3732d98a62ea",
            "f451b98692b64b54a0e8a3643a9bf992",
            "36c1a61163804f9a825638c6c8d962ed",
            "c2d84f324ecd4789b9b3420591f6186d",
            "6d4ec5c2f9624d398f0d9fc27d84cadb",
            "019444645b164b92a8da32e94a443d7e",
            "83bd2cb0ca534108804cdc298d8b26c6",
            "a26e0dce0a86491db71a731f570f1a80",
            "fe61754736d04d539c3f941049b5922a",
            "657a261a272d466e8bfd532279a401a1",
            "5b6eaafac1574f7481e3bb2e20e598b3"
          ]
        },
        "id": "93E9RdnR4D8v",
        "outputId": "51c50846-28b7-408c-c1d9-cd34154b57f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|| 100/100 [23:48<00:00, 14.29s/it, loss=0.0158]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Training**\n",
        "#@markdown\n",
        "#@markdown Takes about an hour. If you don't want to wait, skip to the next cell\n",
        "#@markdown to load pre-trained weights\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "# Exponential Moving Average\n",
        "# accelerates training and improves stability\n",
        "# holds a copy of the model weights\n",
        "ema = EMAModel(\n",
        "    parameters=noise_pred_net.parameters(),\n",
        "    power=0.75)\n",
        "\n",
        "# Standard ADAM optimizer\n",
        "# Note that EMA parametesr are not optimized\n",
        "optimizer = torch.optim.AdamW(\n",
        "    params=noise_pred_net.parameters(),\n",
        "    lr=1e-4, weight_decay=1e-6)\n",
        "\n",
        "# Cosine LR schedule with linear warmup\n",
        "lr_scheduler = get_scheduler(\n",
        "    name='cosine',\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=500,\n",
        "    num_training_steps=len(dataloader) * num_epochs\n",
        ")\n",
        "\n",
        "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
        "    # epoch loop\n",
        "    for epoch_idx in tglobal:\n",
        "        epoch_loss = list()\n",
        "        # batch loop\n",
        "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
        "            for nbatch in tepoch:\n",
        "                # data normalized in dataset\n",
        "                # device transfer\n",
        "                nobs = nbatch['obs'].to(device)\n",
        "                naction = nbatch['action'].to(device)\n",
        "                B = nobs.shape[0]\n",
        "\n",
        "                # observation as FiLM conditioning\n",
        "                # (B, obs_horizon, obs_dim)\n",
        "                obs_cond = nobs[:,:obs_horizon,:]\n",
        "                # (B, obs_horizon * obs_dim)\n",
        "                obs_cond = obs_cond.flatten(start_dim=1)\n",
        "\n",
        "                # sample noise to add to actions\n",
        "                noise = torch.randn(naction.shape, device=device)\n",
        "\n",
        "                # sample a diffusion iteration for each data point\n",
        "                timesteps = torch.randint(\n",
        "                    0, noise_scheduler.config.num_train_timesteps,\n",
        "                    (B,), device=device\n",
        "                ).long()\n",
        "\n",
        "                # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
        "                # (this is the forward diffusion process)\n",
        "                noisy_actions = noise_scheduler.add_noise(\n",
        "                    naction, noise, timesteps)\n",
        "\n",
        "                # predict the noise residual\n",
        "                noise_pred = noise_pred_net(\n",
        "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
        "\n",
        "                # L2 loss\n",
        "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
        "\n",
        "                # optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                # step lr scheduler every batch\n",
        "                # this is different from standard pytorch behavior\n",
        "                lr_scheduler.step()\n",
        "\n",
        "                # update Exponential Moving Average of the model weights\n",
        "                ema.step(noise_pred_net.parameters())\n",
        "\n",
        "                # logging\n",
        "                loss_cpu = loss.item()\n",
        "                epoch_loss.append(loss_cpu)\n",
        "                tepoch.set_postfix(loss=loss_cpu)\n",
        "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
        "\n",
        "# Weights of the EMA model\n",
        "# is used for inference\n",
        "ema_noise_pred_net = noise_pred_net\n",
        "ema.copy_to(ema_noise_pred_net.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F3hUbIuxGdO",
        "outputId": "1c77956b-0006-403d-a9af-ce41def182bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipped pretrained weight loading.\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Loading Pretrained Checkpoint**\n",
        "#@markdown Set `load_pretrained = True` to load pretrained weights.\n",
        "\n",
        "load_pretrained = False\n",
        "if load_pretrained:\n",
        "  ckpt_path = \"pusht_state_100ep.ckpt\"\n",
        "  if not os.path.isfile(ckpt_path):\n",
        "      id = \"1mHDr_DEZSdiGo9yecL50BBQYzR8Fjhl_&confirm=t\"\n",
        "      gdown.download(id=id, output=ckpt_path, quiet=False)\n",
        "\n",
        "  state_dict = torch.load(ckpt_path, map_location='cuda')\n",
        "  ema_noise_pred_net = noise_pred_net\n",
        "  ema_noise_pred_net.load_state_dict(state_dict)\n",
        "  print('Pretrained weights loaded.')\n",
        "else:\n",
        "  print(\"Skipped pretrained weight loading.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "1c17844c76d84675aa1c6e1a973308c8",
            "aa9489756ac24ba0b523f04a3352a09f",
            "51ff5f151bc9475fa3a5c54f8b60a50e",
            "58656f1d31ac45d3aaef45aa22f69899",
            "b9f98d2d7c624a8eae13fa5b422739ce",
            "b72ff2e7020f447fb492c1e9f69a0174",
            "567e3614e80743e5ae1f8e3c75a65b45",
            "187c8fd96f79429bb0752103d5998401",
            "17d07e24261b4627b1160beeb59c5636",
            "269772eda6cc4449bbba9e1e684b442c",
            "7cad813857df45f3ad617c74c68a619e"
          ]
        },
        "id": "OyLjlNQk5nr9",
        "outputId": "a104d1d1-f25a-456d-cac9-520ff50f455f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval PushTStateEnv: 201it [00:29,  6.80it/s, reward=0.927]                          \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score:  0.9268994376868306\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video controls  width=\"256\"  height=\"256\">\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@markdown ### **Inference**\n",
        "\n",
        "# limit enviornment interaction to 200 steps before termination\n",
        "max_steps = 200\n",
        "env = PushTEnv()\n",
        "# use a seed >200 to avoid initial states seen in the training dataset\n",
        "env.seed(100000)\n",
        "\n",
        "# get first observation\n",
        "obs, info = env.reset()\n",
        "\n",
        "# keep a queue of last 2 steps of observations\n",
        "obs_deque = collections.deque(\n",
        "    [obs] * obs_horizon, maxlen=obs_horizon)\n",
        "# save visualization and rewards\n",
        "imgs = [env.render(mode='rgb_array')]\n",
        "rewards = list()\n",
        "done = False\n",
        "step_idx = 0\n",
        "\n",
        "with tqdm(total=max_steps, desc=\"Eval PushTStateEnv\") as pbar:\n",
        "    while not done:\n",
        "        B = 1\n",
        "        # stack the last obs_horizon (2) number of observations\n",
        "        obs_seq = np.stack(obs_deque)\n",
        "        # normalize observation\n",
        "        nobs = normalize_data(obs_seq, stats=stats['obs'])\n",
        "        # device transfer\n",
        "        nobs = torch.from_numpy(nobs).to(device, dtype=torch.float32)\n",
        "\n",
        "        # infer action\n",
        "        with torch.no_grad():\n",
        "            # reshape observation to (B,obs_horizon*obs_dim)\n",
        "            obs_cond = nobs.unsqueeze(0).flatten(start_dim=1)\n",
        "\n",
        "            # initialize action from Guassian noise\n",
        "            noisy_action = torch.randn(\n",
        "                (B, pred_horizon, action_dim), device=device)\n",
        "            naction = noisy_action\n",
        "\n",
        "            # init scheduler\n",
        "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
        "\n",
        "            for k in noise_scheduler.timesteps:\n",
        "                # predict noise\n",
        "                noise_pred = ema_noise_pred_net(\n",
        "                    sample=naction,\n",
        "                    timestep=k,\n",
        "                    global_cond=obs_cond\n",
        "                )\n",
        "\n",
        "                # inverse diffusion step (remove noise)\n",
        "                naction = noise_scheduler.step(\n",
        "                    model_output=noise_pred,\n",
        "                    timestep=k,\n",
        "                    sample=naction\n",
        "                ).prev_sample\n",
        "\n",
        "        # unnormalize action\n",
        "        naction = naction.detach().to('cpu').numpy()\n",
        "        # (B, pred_horizon, action_dim)\n",
        "        naction = naction[0]\n",
        "        action_pred = unnormalize_data(naction, stats=stats['action'])\n",
        "\n",
        "        # only take action_horizon number of actions\n",
        "        start = obs_horizon - 1\n",
        "        end = start + action_horizon\n",
        "        action = action_pred[start:end,:]\n",
        "        # (action_horizon, action_dim)\n",
        "\n",
        "        # execute action_horizon number of steps\n",
        "        # without replanning\n",
        "        for i in range(len(action)):\n",
        "            # stepping env\n",
        "            obs, reward, done, _, info = env.step(action[i])\n",
        "            # save observations\n",
        "            obs_deque.append(obs)\n",
        "            # and reward/vis\n",
        "            rewards.append(reward)\n",
        "            imgs.append(env.render(mode='rgb_array'))\n",
        "\n",
        "            # update progress bar\n",
        "            step_idx += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(reward=reward)\n",
        "            if step_idx > max_steps:\n",
        "                done = True\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "# print out the maximum target coverage\n",
        "print('Score: ', max(rewards))\n",
        "\n",
        "# visualize\n",
        "from IPython.display import Video\n",
        "vwrite('vis.mp4', imgs)\n",
        "Video('vis.mp4', embed=True, width=256, height=256)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "019444645b164b92a8da32e94a443d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03bbeb04a4c44206b1671e69864e69c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0964ed28f2794bdf91e2e2756aae3bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d687f5624cb4871ad167ebcbcb4c148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_116ecf0deb6e44faadb594f2f982c4c2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2db415245cbb44c8ab5c208be328fc16",
            "value": 1
          }
        },
        "116ecf0deb6e44faadb594f2f982c4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d07e24261b4627b1160beeb59c5636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "187c8fd96f79429bb0752103d5998401": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1939a1c3cc7a498fa5f05ac737b0af99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c17844c76d84675aa1c6e1a973308c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa9489756ac24ba0b523f04a3352a09f",
              "IPY_MODEL_51ff5f151bc9475fa3a5c54f8b60a50e",
              "IPY_MODEL_58656f1d31ac45d3aaef45aa22f69899"
            ],
            "layout": "IPY_MODEL_b9f98d2d7c624a8eae13fa5b422739ce"
          }
        },
        "269772eda6cc4449bbba9e1e684b442c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db415245cbb44c8ab5c208be328fc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36c1a61163804f9a825638c6c8d962ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a26e0dce0a86491db71a731f570f1a80",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe61754736d04d539c3f941049b5922a",
            "value": 95
          }
        },
        "3a5463e9f9864ca2b52fe9cd28f4a8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49d5ffd9eb81491f95df70e66c0c94e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a3d8fbcc3e548e1a56d25c10b321e6a",
              "IPY_MODEL_6cf470f12c174e94b0b058cfba9b5fb2",
              "IPY_MODEL_9b6de90b3dbc4877966b2d5233189866"
            ],
            "layout": "IPY_MODEL_4b3aeac3e8e74b8f8dab0dc9ad0b7c94"
          }
        },
        "4b3aeac3e8e74b8f8dab0dc9ad0b7c94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ff5f151bc9475fa3a5c54f8b60a50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_187c8fd96f79429bb0752103d5998401",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17d07e24261b4627b1160beeb59c5636",
            "value": 200
          }
        },
        "5352c2178612408aa84a3732d98a62ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f451b98692b64b54a0e8a3643a9bf992",
              "IPY_MODEL_36c1a61163804f9a825638c6c8d962ed",
              "IPY_MODEL_c2d84f324ecd4789b9b3420591f6186d"
            ],
            "layout": "IPY_MODEL_6d4ec5c2f9624d398f0d9fc27d84cadb"
          }
        },
        "567e3614e80743e5ae1f8e3c75a65b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "583a530a9c0442f2b762b281caa4836d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58656f1d31ac45d3aaef45aa22f69899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269772eda6cc4449bbba9e1e684b442c",
            "placeholder": "",
            "style": "IPY_MODEL_7cad813857df45f3ad617c74c68a619e",
            "value": " 201/? [00:37&lt;00:00,  6.07it/s, reward=0.875]"
          }
        },
        "5b6eaafac1574f7481e3bb2e20e598b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "657a261a272d466e8bfd532279a401a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf470f12c174e94b0b058cfba9b5fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d2c3f8b3714a0d911a132c74589ce1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03bbeb04a4c44206b1671e69864e69c7",
            "value": 0
          }
        },
        "6d4dfa99470e40559bebd6689305f155": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4ec5c2f9624d398f0d9fc27d84cadb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7cad813857df45f3ad617c74c68a619e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82a5a8a6be3a41209de270d5072838a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed0c7c76b76d40c9b25ca92abb00cf34",
            "placeholder": "",
            "style": "IPY_MODEL_3a5463e9f9864ca2b52fe9cd28f4a8b8",
            "value": " 1/1 [00:32&lt;00:00, 32.94s/it, loss=0.0523]"
          }
        },
        "83bd2cb0ca534108804cdc298d8b26c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a3d8fbcc3e548e1a56d25c10b321e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6375a33ca84241b50638edb6321112",
            "placeholder": "",
            "style": "IPY_MODEL_583a530a9c0442f2b762b281caa4836d",
            "value": ""
          }
        },
        "9b6de90b3dbc4877966b2d5233189866": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2331069d969430b87c47e6f11fb2a9e",
            "placeholder": "",
            "style": "IPY_MODEL_c8c282ba14c14da28ba421abc7119cf9",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "a26e0dce0a86491db71a731f570f1a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa9489756ac24ba0b523f04a3352a09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b72ff2e7020f447fb492c1e9f69a0174",
            "placeholder": "",
            "style": "IPY_MODEL_567e3614e80743e5ae1f8e3c75a65b45",
            "value": "Eval PushTStateEnv: "
          }
        },
        "ac6375a33ca84241b50638edb6321112": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2331069d969430b87c47e6f11fb2a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72ff2e7020f447fb492c1e9f69a0174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f98d2d7c624a8eae13fa5b422739ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29b0972b22d4dc59844ea958abf7bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df7b2e7c39944341be1a091331fd7cc6",
              "IPY_MODEL_0d687f5624cb4871ad167ebcbcb4c148",
              "IPY_MODEL_82a5a8a6be3a41209de270d5072838a2"
            ],
            "layout": "IPY_MODEL_6d4dfa99470e40559bebd6689305f155"
          }
        },
        "c2d84f324ecd4789b9b3420591f6186d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657a261a272d466e8bfd532279a401a1",
            "placeholder": "",
            "style": "IPY_MODEL_5b6eaafac1574f7481e3bb2e20e598b3",
            "value": " 95/95 [00:32&lt;00:00,  3.08it/s, loss=0.0484]"
          }
        },
        "c7d2c3f8b3714a0d911a132c74589ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c8c282ba14c14da28ba421abc7119cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df7b2e7c39944341be1a091331fd7cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0964ed28f2794bdf91e2e2756aae3bc4",
            "placeholder": "",
            "style": "IPY_MODEL_1939a1c3cc7a498fa5f05ac737b0af99",
            "value": "Epoch: 100%"
          }
        },
        "ed0c7c76b76d40c9b25ca92abb00cf34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f451b98692b64b54a0e8a3643a9bf992": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019444645b164b92a8da32e94a443d7e",
            "placeholder": "",
            "style": "IPY_MODEL_83bd2cb0ca534108804cdc298d8b26c6",
            "value": "Batch: 100%"
          }
        },
        "fe61754736d04d539c3f941049b5922a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
